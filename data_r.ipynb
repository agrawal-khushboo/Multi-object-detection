{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "LABELS             = ['aeroplane',  'bicycle', 'bird',  'boat',      'bottle', \n",
    "                      'bus',        'car',      'cat',  'chair',     'cow',\n",
    "                      'diningtable','dog',    'horse',  'motorbike', 'person',\n",
    "                      'pottedplant','sheep',  'sofa',   'train',   'tvmonitor']\n",
    "\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "#%% pasring and loading data \n",
    "def parse_annotation(ann_dir, img_dir, labels=[]):\n",
    "    '''\n",
    "    output:\n",
    "    - Each element of the train_image is a dictionary containing the annoation infomation of an image.\n",
    "    - seen_train_labels is the dictionary containing\n",
    "            (key, value) = (the object class, the number of objects found in the images)\n",
    "    '''\n",
    "    all_imgs = []\n",
    "    seen_labels = {}\n",
    "    \n",
    "    for ann in sorted(os.listdir(ann_dir)):\n",
    "        if \"xml\" not in ann:\n",
    "            continue\n",
    "        img = {'object':[]}\n",
    "\n",
    "        tree = ET.parse(ann_dir + ann)\n",
    "        \n",
    "        for elem in tree.iter():\n",
    "            if 'filename' in elem.tag:\n",
    "                path_to_image = img_dir + elem.text\n",
    "                img['filename'] = path_to_image\n",
    "                ## make sure that the image exists:\n",
    "                if not os.path.exists(path_to_image):\n",
    "                    assert False, \"file does not exist!\\n{}\".format(path_to_image)\n",
    "            if 'width' in elem.tag:\n",
    "                img['width'] = int(elem.text)\n",
    "            if 'height' in elem.tag:\n",
    "                img['height'] = int(elem.text)\n",
    "            if 'object' in elem.tag or 'part' in elem.tag:\n",
    "                obj = {}\n",
    "                \n",
    "                for attr in list(elem):\n",
    "                    if 'name' in attr.tag:\n",
    "                        \n",
    "                        obj['name'] = attr.text\n",
    "                        \n",
    "                        if len(labels) > 0 and obj['name'] not in labels:\n",
    "                            break\n",
    "                        else:\n",
    "                            img['object'] += [obj]\n",
    "                            \n",
    "                        \n",
    "\n",
    "                        if obj['name'] in seen_labels:\n",
    "                            seen_labels[obj['name']] += 1\n",
    "                        else:\n",
    "                            seen_labels[obj['name']]  = 1\n",
    "                        \n",
    "\n",
    "                            \n",
    "                    if 'bndbox' in attr.tag:\n",
    "                        for dim in list(attr):\n",
    "                            if 'xmin' in dim.tag:\n",
    "                                obj['xmin'] = int(round(float(dim.text)))\n",
    "                            if 'ymin' in dim.tag:\n",
    "                                obj['ymin'] = int(round(float(dim.text)))\n",
    "                            if 'xmax' in dim.tag:\n",
    "                                obj['xmax'] = int(round(float(dim.text)))\n",
    "                            if 'ymax' in dim.tag:\n",
    "                                obj['ymax'] = int(round(float(dim.text)))\n",
    "\n",
    "        if len(img['object']) > 0:\n",
    "            all_imgs += [img]\n",
    "                        \n",
    "    return all_imgs, seen_labels\n",
    "\n",
    "## Parse annotations \n",
    "#train_image, seen_train_labels = parse_annotation(train_annot_folder,train_image_folder, labels=LABELS)\n",
    "\n",
    "#%%\n",
    "\n",
    "import copy\n",
    "import PIL\n",
    "import scipy\n",
    "class ImageReader(object):\n",
    "    import PIL\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "    def __init__(self,IMAGE_H,IMAGE_W, norm=None):\n",
    "        '''\n",
    "        IMAGE_H : the height of the rescaled image, e.g., 416\n",
    "        IMAGE_W : the width of the rescaled image, e.g., 416\n",
    "        '''\n",
    "        self.IMAGE_H = IMAGE_H\n",
    "        self.IMAGE_W = IMAGE_W\n",
    "        self.norm    = norm\n",
    "        \n",
    "    def encode_core(self,image, reorder_rgb=True):     \n",
    "        # resize the image to standard size\n",
    "#         image = cv2.resize(image, (self.IMAGE_H, self.IMAGE_W))\n",
    "#         image_r = PIL.Image.open(image)\n",
    "        image = scipy.misc.imresize(image,(self.IMAGE_H, self.IMAGE_W,3))\n",
    "#         image = image.resize(self.IMAGE_H, self.IMAGE_W)\n",
    "    \n",
    "        if reorder_rgb:\n",
    "            image = image[:,:,::-1]\n",
    "        if self.norm is not None:\n",
    "            image = self.norm(image)\n",
    "        return(image)\n",
    "    \n",
    "    def fit(self,train_instance):\n",
    "        '''\n",
    "        read in and resize the image, annotations are resized accordingly.\n",
    "        \n",
    "        -- Input -- \n",
    "        \n",
    "        train_instance : dictionary containing filename, height, width and object\n",
    "        \n",
    "        {'filename': 'ObjectDetectionRCNN/VOCdevkit/VOC2012/JPEGImages/2008_000054.jpg',\n",
    "         'height':   333,\n",
    "         'width':    500,\n",
    "         'object': [{'name': 'bird',\n",
    "                     'xmax': 318,\n",
    "                     'xmin': 284,\n",
    "                     'ymax': 184,\n",
    "                     'ymin': 100},\n",
    "                    {'name': 'bird', \n",
    "                     'xmax': 198, \n",
    "                     'xmin': 112, \n",
    "                     'ymax': 209, \n",
    "                     'ymin': 146}]\n",
    "        }\n",
    "        \n",
    "        '''\n",
    "        if not isinstance(train_instance,dict):\n",
    "            train_instance = {'filename':train_instance}\n",
    "                \n",
    "        image_name = train_instance['filename']\n",
    "        image  = np.array(PIL.Image.open(image_name).convert('RGB'))\n",
    "        h, w, c = image.shape\n",
    "        if image is None: print('Cannot find ', image_name)\n",
    "      \n",
    "        image = self.encode_core(image, reorder_rgb=False)\n",
    "            \n",
    "        if \"object\" in train_instance.keys():\n",
    "            \n",
    "            all_objs = copy.deepcopy(train_instance['object'])     \n",
    "\n",
    "            for obj in all_objs:\n",
    "                for attr in ['xmin', 'xmax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_W) / w)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_W), 0)\n",
    "\n",
    "                for attr in ['ymin', 'ymax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_H) / h)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_H), 0)\n",
    "        else:\n",
    "            return image\n",
    "        return image, all_objs\n",
    "\n",
    "#%%\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, confidence=None,classes=None):\n",
    "        self.xmin, self.ymin = xmin, ymin\n",
    "        self.xmax, self.ymax = xmax, ymax\n",
    "        ## the code below are used during inference\n",
    "        # probability\n",
    "        self.confidence      = confidence\n",
    "        # class probaiblities [c1, c2, .. cNclass]\n",
    "        self.set_class(classes)\n",
    "        \n",
    "    def set_class(self,classes):\n",
    "        self.classes = classes\n",
    "        self.label   = np.argmax(self.classes) \n",
    "        \n",
    "    def get_label(self):  \n",
    "        return(self.label)\n",
    "    \n",
    "    def get_score(self):\n",
    "        return(self.classes[self.label])\n",
    "#%%\n",
    "class BestAnchorBoxFinder(object):\n",
    "    def __init__(self, ANCHORS):\n",
    "        '''\n",
    "        ANCHORS: a np.array of even number length e.g.\n",
    "        \n",
    "        _ANCHORS = [4,2, ##  width=4, height=2,  flat large anchor box\n",
    "                    2,4, ##  width=2, height=4,  tall large anchor box\n",
    "                    1,1] ##  width=1, height=1,  small anchor box\n",
    "        '''\n",
    "        self.anchors = [BoundBox(0, 0, ANCHORS[2*i], ANCHORS[2*i+1]) \n",
    "                        for i in range(int(len(ANCHORS)//2))]\n",
    "        \n",
    "    def _interval_overlap(self,interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                 return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x3  \n",
    "\n",
    "    def bbox_iou(self,box1, box2):\n",
    "        intersect_w = self._interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "        intersect_h = self._interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
    "\n",
    "        intersect = intersect_w * intersect_h\n",
    "\n",
    "        w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "        w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "        union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "        return float(intersect) / union\n",
    "    \n",
    "    def find(self,center_w, center_h):\n",
    "        # find the anchor that best predicts this box\n",
    "        best_anchor = -1\n",
    "        max_iou     = -1\n",
    "        # each Anchor box is specialized to have a certain shape.\n",
    "        # e.g., flat large rectangle, or small square\n",
    "        shifted_box = BoundBox(0, 0,center_w, center_h)\n",
    "        ##  For given object, find the best anchor box!\n",
    "        for i in range(len(self.anchors)): ## run through each anchor box\n",
    "            anchor = self.anchors[i]\n",
    "            iou    = self.bbox_iou(shifted_box, anchor)\n",
    "            if max_iou < iou:\n",
    "                best_anchor = i\n",
    "                max_iou     = iou\n",
    "        return(best_anchor,max_iou)    \n",
    "\n",
    "#%%\n",
    "def rescale_centerxy(obj,config):\n",
    "    '''\n",
    "    obj:     dictionary containing xmin, xmax, ymin, ymax\n",
    "    config : dictionary containing IMAGE_W, GRID_W, IMAGE_H and GRID_H\n",
    "    '''\n",
    "    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "    center_x = center_x / (float(config['IMAGE_W']) / config['GRID_W'])\n",
    "    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "    center_y = center_y / (float(config['IMAGE_H']) / config['GRID_H'])\n",
    "    return(center_x,center_y)\n",
    "\n",
    "def rescale_cebterwh(obj,config):\n",
    "    '''\n",
    "    obj:     dictionary containing xmin, xmax, ymin, ymax\n",
    "    config : dictionary containing IMAGE_W, GRID_W, IMAGE_H and GRID_H\n",
    "    '''    \n",
    "    # unit: grid cell\n",
    "    center_w = (obj['xmax'] - obj['xmin']) / (float(config['IMAGE_W']) / config['GRID_W']) \n",
    "    # unit: grid cell\n",
    "    center_h = (obj['ymax'] - obj['ymin']) / (float(config['IMAGE_H']) / config['GRID_H']) \n",
    "    return(center_w,center_h)\n",
    "#%%\n",
    "import numpy as np \n",
    "from keras.utils import Sequence\n",
    "\n",
    "class SimpleBatchGenerator(Sequence):\n",
    "    def __init__(self, images, config, norm=None, shuffle=True):\n",
    "        '''\n",
    "        config : dictionary containing necessary hyper parameters for traning. e.g., \n",
    "            {\n",
    "            'IMAGE_H'         : 416, \n",
    "            'IMAGE_W'         : 416,\n",
    "            'GRID_H'          : 13,  \n",
    "            'GRID_W'          : 13,\n",
    "            'LABELS'          : ['aeroplane',  'bicycle', 'bird',  'boat',      'bottle', \n",
    "                                  'bus',        'car',      'cat',  'chair',     'cow',\n",
    "                                  'diningtable','dog',    'horse',  'motorbike', 'person',\n",
    "                                  'pottedplant','sheep',  'sofa',   'train',   'tvmonitor'],\n",
    "            'ANCHORS'         : array([ 1.07709888,   1.78171903,  \n",
    "                                        2.71054693,   5.12469308, \n",
    "                                        10.47181473, 10.09646365,  \n",
    "                                        5.48531347,   8.11011331]),\n",
    "            'BATCH_SIZE'      : 16,\n",
    "            'TRUE_BOX_BUFFER' : 50,\n",
    "            }\n",
    "        \n",
    "        '''\n",
    "        self.config = config\n",
    "        self.config[\"BOX\"] = int(len(self.config['ANCHORS'])/2)\n",
    "        self.config[\"CLASS\"] = len(self.config['LABELS'])\n",
    "        self.images = images\n",
    "        self.bestAnchorBoxFinder = BestAnchorBoxFinder(config['ANCHORS'])\n",
    "        self.imageReader = ImageReader(config['IMAGE_H'],config['IMAGE_W'],norm=norm)\n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.images)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        == input == \n",
    "        \n",
    "        idx : non-negative integer value e.g., 0\n",
    "        \n",
    "        == output ==\n",
    "        \n",
    "        x_batch: The numpy array of shape  (BATCH_SIZE, IMAGE_H, IMAGE_W, N channels).\n",
    "            \n",
    "            x_batch[iframe,:,:,:] contains a iframeth frame of size  (IMAGE_H,IMAGE_W).\n",
    "            \n",
    "        y_batch:\n",
    "\n",
    "            The numpy array of shape  (BATCH_SIZE, GRID_H, GRID_W, BOX, 4 + 1 + N classes). \n",
    "            BOX = The number of anchor boxes.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,:4] contains (center_x,center_y,center_w,center_h) \n",
    "            of ianchorth anchor at  grid cell=(igrid_h,igrid_w) if the object exists in \n",
    "            this (grid cell, anchor) pair, else they simply contain 0.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,4] contains 1 if the object exists in this \n",
    "            (grid cell, anchor) pair, else it contains 0.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,5 + iclass] contains 1 if the iclass^th \n",
    "            class object exists in this (grid cell, anchor) pair, else it contains 0.\n",
    "\n",
    "\n",
    "        b_batch:\n",
    "\n",
    "            The numpy array of shape (BATCH_SIZE, 1, 1, 1, TRUE_BOX_BUFFER, 4).\n",
    "\n",
    "            b_batch[iframe,1,1,1,ibuffer,ianchor,:] contains ibufferth object's \n",
    "            (center_x,center_y,center_w,center_h) in iframeth frame.\n",
    "\n",
    "            If ibuffer > N objects in iframeth frame, then the values are simply 0.\n",
    "\n",
    "            TRUE_BOX_BUFFER has to be some large number, so that the frame with the \n",
    "            biggest number of objects can also record all objects.\n",
    "\n",
    "            The order of the objects do not matter.\n",
    "\n",
    "            This is just a hack to easily calculate loss. \n",
    "        \n",
    "        '''\n",
    "        l_bound = idx*self.config['BATCH_SIZE']\n",
    "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
    "\n",
    "        if r_bound > len(self.images):\n",
    "            r_bound = len(self.images)\n",
    "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
    "\n",
    "        instance_count = 0\n",
    "        \n",
    "        ## prepare empty storage space: this will be output\n",
    "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\n",
    "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
    "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\n",
    "\n",
    "        for train_instance in self.images[l_bound:r_bound]:\n",
    "            # augment input image and fix object's position and size\n",
    "            img, all_objs = self.imageReader.fit(train_instance)\n",
    "            \n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "            \n",
    "            for obj in all_objs:\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
    "                    center_x, center_y = rescale_centerxy(obj,self.config)\n",
    "                    \n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "\n",
    "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
    "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
    "                        center_w, center_h = rescale_cebterwh(obj,self.config)\n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "                        best_anchor,max_iou = self.bestAnchorBoxFinder.find(center_w, center_h)\n",
    "                                \n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        # it could happen that the same grid cell contain 2 similar shape objects\n",
    "                        # as a result the same anchor box is selected as the best anchor box by the multiple objects\n",
    "                        # in such ase, the object is over written\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box # center_x, center_y, w, h\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1. # ground truth confidence is 1\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1 # class probability of the object\n",
    "                        \n",
    "                        # assign the true box to b_batch\n",
    "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
    "                        \n",
    "                        true_box_index += 1\n",
    "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "                            \n",
    "            x_batch[instance_count] = img\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1  \n",
    "        return [x_batch, b_batch], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.images)\n",
    "\n",
    "\n",
    "\n",
    "#referance: https://github.com/experiencor/keras-yolo2\n",
    "#           https://fairyonice.github.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
